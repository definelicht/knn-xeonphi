\section{$k$-Nearest Neighbor Search}
  %\label{sec:_k_nearest_neighbor_search_algorithm}
  \label{sec:background}

  In this section we formally define the $k$-nearest neighbor search problem 
  and introduce the algorithm to build a randomized k-d tree.

  \mypar{Nearest neighbor search} Consider a set of points $\mathcal{P} 
  = \{p_1,p_2,\dots,p_n\}$ in a metric space $\mathbb{M}$ which defines some 
  distance function $d\colon\mathbb{M}\times\mathbb{M}\to\mathbb{R}$.  If we 
  are given a query point $q\in\mathcal{P}$, the nearest neighbor of $q$ must 
  satisfy the condition
  \begin{align}
    \label{eq:NN}
    \operatorname{NN}(q,\mathcal{P}) &= \operatorname{argmin}_{x\in\mathcal{P}} 
    d(q,x)\in\mathcal{P}.
  \end{align}

  Often we are not interested in only one nearest neighbor, but the $k$~nearest 
  neighbors, for which we use the notation
  \begin{align}
    \label{eq:kNN}
    \operatorname{kNN}(q,\mathcal{P},k) &= \mathcal{A},
  \end{align}
  where $\mathcal{A}\subseteq\mathcal{P}$ with cardinality 
  $\vert\mathcal{A}\vert = k$.  The following constraint must further be 
  satisfied
  \begin{align}
    \label{eq:constraint_kNN}
    \{d(q,x)\mid d(q,x)\leq d(q,y)\forall x\in\mathcal{A}, 
    y\in\mathcal{P}-\mathcal{A},q\in\mathcal{P}\}.
  \end{align}
  Since the cardinality of $\mathcal{A}$ is $k$, it follows that $n\geq k$ for 
  the number of points in $\mathcal{P}$.

  \mypar{Randomized k-d~tree build} Building the tree is similar to a conventional 
  k-d tree as described in~\cite{bentley1975a,friedman1977a}, but rather than choosing the dimension used to split the data deterministically, 
  the data is split % in a $d$-dimensional metric space along 
  in along some dimension $d$ chosen randomly among the $D$ dimensions with highest variance. Each point 
  $\pmb{p}\in\mathcal{P}$, for which the value of the $p_i$ dimension is lower than 
  the value of the median in the chosen dimension at the current node, is 
  placed in a reduced set of points $\mathcal{P}_l\subset\mathcal{P}$ or 
  $\mathcal{P}_r\subset\mathcal{P}$ otherwise, where 
  $\mathcal{P}_l\cup\mathcal{P}_r = \mathcal{P}$.
  The procedure is then recursively applied to the two new branches using the 
  corresponding set of points $\mathcal{P}=\mathcal{P}_l$ or 
  $\mathcal{P}=\mathcal{P}_r$ with a new random choice for the split dimension 
  $d$. % The recursion bottoms out for $\left|P\right|=1$, where the remaining point is stored as a leaf, resulting in a total of $2\left|P\right|-1$ nodes.
  % For the work presented here, we follow~\cite{muja2009a} and set $D=5$.
  
  \mypar{Randomized k-d~tree search}
Multiple randomized k-d trees are searched for $k$ nearest neighbors. For each query two bounded heaps $H_{1}$ and $H_{2}$ are maintained across the randomized k-d forest. $H_{1}$ tracks the $k$ closest neighbors and $H_{2}$ maintains the most promising branches not yet searched across all trees according to the distance from the query point their along their split dimension. The algorithm first recurses to the bottom once, storing the most promising branches encounted during
the recursion in $H_{2}$, then pops the lowest distance branch from $H_{2}$ and repeats the process. After inspecting some maximum number of leaves $m<\left|\mathcal{P}\right|$ among all the randomized trees, the search returns the $k$ closest neighbors found as an approximation of the true $k$ nearest neighbors. As such, $m$ is the parameter that determines the trade-off between accuracy and speed ($m=\left|\mathcal{P}\right|$ falls back to the conventional k-d tree
algorithm, returning an exact result).
  % Give a short, self-contained summary of necessary
  % background information. For example, assume you present an
  % implementation of sorting algorithms. You could organize into sorting
  % definition, algorithms considered, and asymptotic runtime statements. The goal of the
  % background section is to make the paper self-contained for an audience
  % as large as possible. As in every section
  % you start with a very brief overview of the section. Here it could be as follows: In this section 
  % we formally define the sorting problem we consider and introduce the algorithms we use
  % including a cost analysis.

  % \mypar{Sorting}
  % Precisely define sorting problem you consider.

  % \mypar{Sorting algorithms}
  % Explain the algorithm you use including their costs.

  % As an aside, don't talk about "the complexity of the algorithm.'' It's incorrect,
  % problems have a complexity, not algorithms.

  % mainfile: ./../report.tex
